* Graphics Programming
** OpenGL
*** What is OpenGL?
OpenGL is considered an API or specification that tells graphic driver developers (NVIDIA, AMD or Intel) what a function
should do and how it should behave.  Because of this, each implementation can be a little bit different, although the
function result has to be the same.

*** OpenGL Websites
API documentation: https://docs.gl/ Learn OpenGL: https://learnopengl.com/Getting-started/OpenGL

*** Core-profile vs. Immediate Mode
Immediate mode is the old way of doing things. Although OpenGL is easier to use with that mode, it's also very
inefficient.  For that reason, we use *Core-profile* mode. The latter offers more flexibility but it's harder.

*** State machine
OpenGL is a big state machine, which means that it always has a context. We can change or use this context by calling
OpenGL functions.

*** 3D space
Everything in OpenGL is in 3D space, but since screens are in 2D there exists a process that transforms 3D coordinates
to 2D. This is done in the [[Graphics Pipeline][Graphics Pipeline]].

*** Graphics Pipeline
It's a series of phases where two main events happen:

1) 3D coordinates are transformed into 2D. This is done at the "first part" of the pipeline.
2) 2D coordinates are transformed into colored pixels. This is done at the "second part" of the pipeline.

The pipeline is composed of different steps or phases, where each one requires as input the output of the previous phase
or step.  The great benefit of this pipeline is that we can parallelize it.  Because graphic cards have a lot of cores,
they can process our data quickly in programs that are called [[Shaders][shaders]].

Initially, we give the pipeline, as input, the [[Vertex Data][vertex data]].

#+CAPTION: Pipeline
#+NAME: Pipeline.png
[[./Pipeline.png]]

The blue background colored phases or steps are the ones where we can inject our own shaders.

Goal of each step:

1. *Vertex Shader*: transform 3D coordinates into "different" 3D coordinates. This shader also allows us to tinker with
   vertex attributes. These coordinates need to be [[Normalized Device Coordinates][normalized]]. Input variables within this shader are usually referred
   to as [[Vertex Attributes][vertex attributes]].
2. *Geometry Shader*: the output of the vertex shader is passed to this one. This shader can generate new shapes using the
   ones we gave it. In the image above, we can see that it creates a second triangle. This shader is _optional_.
3. *Shape Assembly*: the output of the geometry shader or vertex is passed to this one. It takes these vertices or vertex
   (depending on the [[Primitives][primitive]] selected) and assembles all the points.
4. *Rasterization*: takes the output of the shape assembly as input and maps the _resulting primitives_ to actual pixels on
   the screen. The result is called [[Fragment][fragments]], and they're passed to the fragment shader. Before they're passed,
   [[Clipping][clipping]] is performed.
5. *Fragment Shader*: takes fragments as input and its goal is to compute the color for each one of the pixels. In this
   step is where all the magic effects happen.
6. *Tests and Blending*: after the color is determined for each pixel, two more events happen, [[Alpha Test][alpha test]] and
   [[Blending][blending]]. Both can be summarized as a process where opacity and blending of different objects are computed.

In modern OpenGL, we are *required* to define at least one vertex and fragment shader, otherwise the program won't run
correctly.

*** Shaders
They're basically programs that run in the GPU. They need to be created, compiled and when we link them together they
produce a [[Shader Program][shader program]].  Since we need to create shaders, we also need to _delete them_.

A shader typically has the following structure:

#+NAME: Typical shader program
#+BEGIN_SRC glsl
  #version version_number
  in type in_variable_name;
  in type in_variable_name;

  out type out_variable_name;

  uniform type uniform_name;

  void main() {
    // process input and do something...

    // output processed stuff to output variable
    out_variable_name = weird_stuff_processed;
  }
#+END_SRC

We can pass data between shaders (contiguous) if input and output variables have the same name and type. When we link the shaders
together, OpenGL will take care of that.

*** Shader Program
Linked version of multiple shaders combined.  To create a shader program, first, we need to create a program, then
attach the corresponding shaders and finally link them:

#+NAME: Example of creation of shader program.
#+BEGIN_SRC cpp
  unsigned int shaderProgram;
  shaderProgram = glCreateProgram();
  glAttachShader(shaderProgram, vertexShader);
  glAttachShader(shaderProgram, fragmentShader);
  glLinkProgram(shaderProgram);
#+END_SRC

To use it, we call the glUseProgram() function.

*** Vertex Data
It's an array of 3D coordinates (vertices) that should form a triangle.

*** Vertex Format
It refers to all the information (layout of data) associated with each vertex in an 3D object.
It encompasses all the attributes that define a vertex.

*** Vertex Attributes
They are the individual properties of a particular vertex. A vertex can have different properties, for example, its
color and position. We can add more attributes or properties to a vertex.

We have to manually tell OpenGL what's the size in bytes of the information to a particular vertex.

#+CAPTION: Vertex Attributes and Data Example
#+NAME: VertexAttributesAndData.png
[[./VertexAttributesAndData.png]]

In this example:

- Each coordinate is a float (4 bytes, 32 bits).
- Each coordinate has three components: X, Y and Z.
- Values are _tighly packed_.

To inform OpenGL about this, we use the function glVertexAttribPointer.

*** Primitives
Hints we give to OpenGL to tell it how we want to draw our [[Vertex Data][vertex data]].  Some of these hints are:

1. GL_POINTS.
2. GL_TRIANGLES.
3. GL_LINE_STRIP.

*** Clipping
Process that ignores parts or sections of shapes that are not going to be rendered on the screen.  For example, if we're
looking forward, and we have a very extensive image in front of us, clipping will be performed on left and right,
because we can't see it completely.  This process improves performance.

*** Fragment
It's all the data required to render a single pixel on the screen.

*** Alpha Test
Process where object's opacity is determined.

*** Blending
Process where OpenGL determines if one object is in front of another (for example) and blends them accordingly.

*** Normalized Device Coordinates
X, Y and Z coordinates that range from [-1.0, 1.0].

*** Vertex Buffer Object (VBO)
It's a chunk of memory that we use store all the vertices of a particular object. It can contain information such as
position, color, normals, etc.

When we use VBOs we also have to tell OpenGL how we want the GPU to interpret the data that's inside, among other things.

Its buffer type is _GL_ARRAY_BUFFER_.

*** GLSL (OpenGL Shading Language)
Programming language used to program shaders in OpenGL.

*** Vectors in GLSL
In GLSL, a vector is composed of 4 components: x, y, z and w. W represents something called _perspective division_.

*** Perspective division
TODO

*** Vertex Array Object (VAO)
It's a container or a manager that stores all the state-related settings needed to render a particular object.

In other words, it stores the current bound [[Vertex Buffer Object][VBO]] for us to use it later.

This is very useful to save us from writing a lot of code, because when we want to draw something to the screen we need
to do a series of steps.

The workflow would look like this:

1) Set up the vertex data, i.e, define vertices for a triangle.
2) Set up the vertex format, i.e, define the layout of the vertex attributes.
3) Create and bind a VAO, that way we save the current context.
4) Link the VAO to the VBO.
5) Render the triangle using the VAO.

We can reuse VAOs (_shared VAOS_) if multiple objects have the same vertex format and rendering settings. However, if
objects need to have, say, different shaders, then we'd need to use more than one VAO.

_Modern OpenGL requires to use at least one VAO._

*** Element Buffer Object (EBO)
They're buffers that store the order (_indices_) in which we want vertices to be drawn.

When we use this approach to draw things, we're doing [[Indexed Drawing][indexed drawing]]. Indices start from 0.

We also need to bind them, just like [[Vertex Buffer Object][VBOs]], however, the main difference is that we'll use GL_ELEMENT_ARRAY_BUFFER when
binding, and then we'll use glDrawElements instead of glDrawArrays.

[[Vertex Array Object (VAO)][VAOs]] also store EBOs.

NOTE:

A VAO stores the glBindBuffer calls when the target is GL_ELEMENT_ARRAY_BUFFER. This also means it stores its unbind
calls so make sure you don't unbind the element array buffer before unbinding your VAO, otherwise it doesn't have an EBO
configured.

*** Indexed Drawing
TODO

*** Wireframe Mode
It's a mode that draws only the edges of triangles.

*** Uniforms
Are global variables that live within shaders. They're useful when we need to change something -like a color- every
frame or to pass information between shaders, since they're shared among all shaders that are linked together.

The syntax is:

#+NAME: Example of uniform variable
#+BEGIN_SRC glsl
  uniform vec4 myColor;
#+END_SRC

The way we initialize the uniform from our program/application (and also our CPU) is by invoking the function
glUniform4f (or similar ones):

#+NAME: Example of uniform variable
#+BEGIN_SRC glsl
  int vertexColorLocation = glGetUniformLocation(shaderProgram, "ourColor");
  glUseProgram(shaderProgram);
  glUniform4f(vertexColorLocation, 0.0f, greenValue, 0.0f, 1.0f);
#+END_SRC

_NOTE_:

If you declare a uniform that isn't used anywhere in your GLSL code the compiler will silently remove the variable from
the compiled version which is the cause for several frustrating errors; keep this in mind!

*** Texture Wrapping
When the texture coordinates fall outside the range, there are multiple behaviors available:

- GL_REPEAT: repeats the texture image.
- GL_MIRRORED_REPEAT: same as GL_REPEAT but mirrors the image in each repetition.
- GL_CLAMP_TO_EDGE: clamps between 0 and 1. Stretch effect.
- GL_CLAMP_TO_BORDER: coordinates outside the range are given a user-specified border color.

#+CAPTION: Texture Wrapping Example
#+NAME: TextureWrapping.png
[[./TextureWrapping.png]]

When setting these options, we have the ability to do it per coordinate-axis. Here, x, y and z are called:

- s -> x
- t -> y
- r -> z

#+NAME: Example
#+BEGIN_SRC cpp
  glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_MIRRORED_REPEAT);
  glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT);
#+END_SRC

*** Texture Filtering
It's how OpenGL determines the color of a pixel on a textured object. When we give a floating point number, for example,
0.5f, then OpenGL looks at nearby [[Texel][texels]] and blends their color together ([[Interpolation][interpolation]]), outputting the final colored
pixel.

There are two types of filtering:

- GL_NEAREST: nearest point or point filtering. It's the default one. OpenGL selects the texel that center is closest to
  the texture coordinate.

#+CAPTION: Nearest Filtering
#+NAME: NearestFiltering.png
[[./NearestFiltering.png]]

- GL_LINEAR: bilinear filtering. OpenGL takes an interpolated value from the neighboring texels, approximating a color.

#+CAPTION: Linear Filtering
#+NAME: LinearFiltering.png
[[./LinearFiltering.png]]

We can also use these two filtering options for [[Magnifying][magnifying]] or [[Minifying][minifying]] operations.

*** Texel
Texture pixel.

*** MipMaps
MipMaps are textures that OpenGL uses when rendering objects that are far away from the viewer.

They're optimized and scaled down (twice per object) and OpenGL uses one or the other depending on the distance from the
viewer to the object.

As OpenGL changes from one texture to another, it may produce visible sharp edges between the two textures.

Example:

#+CAPTION: MipMap
#+NAME: MipMap.png
[[./MipMap.png]]

As with regular textures, we can apply [[Texture Filtering][texture filtering]] too.

Options are:

- GL_NEAREST_MIPMAP_NEAREST: takes nearest mipmap to match the pixel size and uses nearest neighbor interpolation for
  texture sampling.

- GL_LINEAR_MIPMAP_NEAREST: takes nearest mipmap level and samples that level using linear interpolation.

- GL_NEAREST_MIPMAP_LINEAR: linearly interpolates between the two mipmaps that most closely match the size of a pixel
  and samples the interpolated level via nearest neighbor interpolation.

- GL_LINEAR_MIPMAP_LINEAR: linearly interpolates between the two closest mipmaps and samples the interpolated level via
  linear interpolation.

#+NAME: Setting filtering method for mipmaps
#+BEGIN_SRC cpp
  glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
  glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
#+END_SRC

_NOTE_:

A common mistake is to set one of the mipmap filtering options as the magnification filter. This doesn't have any
effect since mipmaps are primarily used for when textures get downscaled: texture magnification doesn't use mipmaps
and giving it a mipmap filtering option will generate an OpenGL GL_INVALID_ENUM error code.

*** Texture Unit
It's like a "shelf" where we can store a different number of textures, usually up to 16 (hardware dependant).

GL_TEXTURE_0 -> GL_TEXTURE_15

This means we can use up to 16 textures in a single shader.

** Render Loop
The render loop is the main loop of the program where we _typically_ do 3 things: *process keyboard input*, *render stuff* and
finally *draw to the screen*.  Statements executed within this loop are said to be executed in _one frame_.  Because of
this, it's important for functions within this section to be as fast as possible.
** GLSL
It's the language that we use to write shaders. Similar to C.

It contains useful features to work with vectors and matrices.

Types supported:

- uint
- int
- float
- double
- bool

Containers available:

- vectors (n represents the number of components, [2, 4])
  Components are: x, y, z and w.

  Type of vectors:

  - vecn (floats)
  - bvecn (boolean)
  - ivecn (integers)
  - uvecn (unsigned integers)
  - dvecn (double)

- matrices

*** Swizzling
It's a syntax feature of GLSL that allows us to create vectors in a fancy way.

For example:

#+NAME: Typical shader program
#+BEGIN_SRC glsl
  void main() {
    vec2 someVec;
    vec4 differentVec = someVec.xyxx;
    vec3 anotherVec = differentVec.zyw;
    vec4 otherVec = someVec.xxxx + anotherVec.yxzy;
  }
#+END_SRC

** Interpolation
Imagine we had a right triangle with three vertices.

Each vertex has a different color, for example, red, green and blue.

Now, within the triangle there are a lot of fragments or pixels that are in-between these vertices, and because a change
of color need to happen as we approach to one of the vertices, OpenGL computes a mix of colors with a smooth transition
for each fragment. That process is called interpolation.

For example, if we look from the red vertex to the green one, we'd see the color yellow exactly in the middle of the
trajectory. As we approach the green vertex, the color will smoothly be converting to green.

** Texture
It's an image that can be 1D, 2D or 3D that we use to add detail to an object.

Coordinates go from (0,0), which is lower left corner, to (1,1) upper right corner.

Example:

#+CAPTION: Texture Coordinates Example
#+NAME: TextureCoordinates.png
[[./TextureCoordinates.png]]

What if we go outside this range? See [[Texture Wrapping][texture wrapping]].

** Sampling
It refers to the process of obtaining the texture color from the texture's coordinates.
** Magnifying
Scaling up a texture.

** Minifying
Scaling down a texture.

** Mathematics
*** Vectors
Are just directions. They have a direction and a magnitude.

We generally work with vectors from 2D to 4D.

The direction tells us where the vector is heading to: left, right, up, down, etc.

The magnitude (also known as strength or length) tells us how many "steps" or "units" we have to walk until we reach our
destination.

It's like a treasure map: (1, 3) means walk 1 step rightwards, then 3 steps upwards.

Because they're directions, we don't care about the origin of them to define equality. For example, these two vectors w
and v are equal:

#+CAPTION: Equal vectors
#+NAME: EqualVectors.png
[[./EqualVectors.png]]

Vectors in formulas are represented like this:

#+CAPTION: Vector Representation
#+NAME: VectorDefinition.png
[[./VectorDefinition.png]]

When we want to represent a vector as a coordinate or position, we pick an origin, generally (0, 0, 0), and from there
we draw a line pointing to the position or point that we want. This is called a _position vector_.
We could also pick some other origin and then say: "this vector points to that point in space from this origin".

Using vectors we can represent _positions_ and _directions_ in 2D and 3D space.

**** Scalar Vector Operations
When we say scalar we just mean a constant. It's just about multiplying a vector by a constant.

Addition, subtraction, multiplication and division by a scalar consists on adding/subtract/multiply and divide each
vector component by that scalar, and that's it.

For example:

#+CAPTION: Vector Scalar Operations
#+NAME: VectorScalarOperations.png
[[./VectorScalarOperations.png]]

This has the effect of [[Scaling][scaling]] the vector by some amount. For example: zooming in and out.

**** Vector Negation
When we negate a vector we get the same vector but in the reversed direction.

If we have a vector that points to north-east and we negate it, we'd get a vector pointing to south-west.

It's just about flipping the sign of each vector component, which means multiplying it by -1!

#+CAPTION: Vector Negation
#+NAME: VectorNegation.png
[[./VectorNegation.png]]

**** Addition and Subtraction
Both operations are _component wise_:

#+CAPTION: Vector Addition and Subtraction
#+NAME: VectorAddSub.png
[[./VectorAddSub.png]]

If we had two vectors, v(4, 2) k(1, 2) and we'd add them together, we'd get a new vector that points directly to the end
point, something like this:

#+CAPTION: Adding Two Vectors Representation
#+NAME: AddingTwoVectors.png
[[./AddingTwoVectors.png]]

Related stuff: [[Parallelogram Law][parallelogram law]].

Subtraction yields another vector that's the difference between the two points the vectors are pointing at.
In other words, we get a vector that points from the end of the first vector to the end of the second vector.
Like this:

#+CAPTION: Subtracting Two Vectors Representation
#+NAME: SubtractingTwoVectors.png
[[./SubtractingTwoVectors.png]]

**** Length
It can be understood as the distance or units we have to travel from an origin to the end point of a vector. This
distance is in a straight line, meaning it's the shortest distance to get to that end point.

We obtain it using Pythagoras theorem, because we can represent the vector as a rectangle triangle:

#+CAPTION: Magnitude or Length of a Vector
#+NAME: MagnitudeLengthVector.png
[[./MagnitudeLengthVector.png]]

We can even extend this to 3D by adding the \(^{z^2}\) to the equation.

**** Unit Vector
It's just a vector but with an important property: it's length is 1.

This happens after [[Normalizing Vectors][normalizing]] a vector.

We can calculate a unit vector from any vector by dividing each component by its length, like this:

\(\hat{n} = \frac{\vec{v}}{\|\vec{v}\|}\)

**** Normalizing Vectors
Normalizing a vector means dividing each vector's component by the length of the vector.

By doing this, we'll get a new vector that points in the same direction but with length 1.

It's particularly useful when comparing different vectors.

But what does it mean to normalize a vector? Here's an example:

Imagine you have a bunch of arrows, each pointing in a different direction and with different lengths. Some arrows are
longer, and some are shorter. Now, let's say you want to compare how strong each arrow is in pushing something. But the
problem is, it's hard to tell how strong they are just by looking at them because some are longer than others.

So, to make it fair and easier to compare, we decide to make all the arrows the same length. We don't care about their
original lengths; we just want to see how strong they are compared to each other when they're all the same length.

In math, vectors are like those arrows, and their 'strength' is how long they are. When we normalize a vector, we're
making all the vectors the same length, like making all the arrows the same length. This makes it easier to compare and
work with vectors in math and computer graphics.

**** Vector-to-Vector Multiplication
There's two ways of multiplying matrices: dot and cross product.

***** Dot Product
The dot product of two vectors is the product of their lengths times the cosine of the angle between them.

\(\vec{v} \cdot \vec{k} = \|\vec{v}\| \cdot \|\vec{k}\| \cdot \cos \theta\)

If v and k were [[Unit Vector][unit vectors]] then we can say that _the dot product of two vectors defines the angle between them_.

The letter (θ) is theta.

Considering that the cosine of 90º is 0 and the cosine of 0º is 1, then we could _test, using the dot product, if two
vectors are parallel or orthogonal to each other_. Orthogonal means perpendicular, which means that the two vectors form
a right angle (90º).

It's just a _component-wise_ multiplication where we add the results together.

#+CAPTION: Dot Product
#+NAME: DotProduct.png
[[./DotProduct.png]]

Having the dot product and knowing that theta can be obtained with the inverse of the cosine, then we have:

\(\theta = \cos^{-1}(\vec{a} \cdot \vec{b})\)
\(\theta = \cos^{-1}(-0.8)\)

Which yields a degree of 143,1.

***** Cross Product
It's only defined in 3D space.

The output of this operation is a new vector that is orthogonal to both.

#+CAPTION: Cross Product Representation
#+NAME: CrossProduct.png
[[./CrossProduct.png]]

This is the formula. To really understand what's going on I should learn more linear algebra:

#+CAPTION: Cross Product Formula
#+NAME: CrossProductFormula.png
[[./CrossProductFormula.png]]

*** Matrices
They're a rectangular array of numbers. Classic NxM array. NxM are called the _dimensions_ of the matrix.

Each number is called an _element_ of the matrix.

**** Matrix Addition and Subtraction
Additions and subtractions are only defined for matrices with the same dimensions.

They're _element-wise_ operations.

#+CAPTION: Addition and Subtraction of Matrices
#+NAME: AddSubMatrices.png
[[./AddSubMatrices.png]]

**** Matrix-scalar products
It's similar to vectors. We multiply the scalar times each component:

#+CAPTION: Matrix-scalar product
#+NAME: MatrixScalarMultiplication.png
[[./MatrixScalarMultiplication.png]]

**** Matrix-Matrix Multiplication
There are restrictions to multiply matrices:

1. _We can only multiply matrices if the number of columns of the left-hand side matrix is equal to the number of rows of
   the right-hand side matrix_.
2. _It's not commutative, meaning A · B != B · A_.

Example:

#+CAPTION: Matrix-Matrix Multiplication
#+NAME: MatrixMatrixMultiplication.png
[[./MatrixMatrixMultiplication.png]]

The output matrix is one with (N, M) dimensions, where N is the number of rows of the left-hand side matrix and M is the
number of columns of the right-hand side matrix.

*** Matrix-Vector Multiplication
If we have a MxN matrix and we have a Nx1 vector, multiplication is defined.

There are interesting properties when we perform these kind of multiplications.

_Multiplying that matrix with the vector transforms the vector!_

**** Identity Matrix
One _transformation_ matrix that we can think of is the _identity matrix_.

This matrix is just a NxN matrix with all 0's except on its diagonal, which is filled with 1's.

When we multiply a vector by this matrix, it leaves the vector unchanged:

#+CAPTION: Identity Matrix
#+NAME: IdentityMatrix.png
[[./IdentityMatrix.png]]

**** Scaling
There are two types of scaling: _non-uniform_ and _uniform_.

- Non-uniform: when we scale the matrix with different factors per axis.
- Uniform: when we scale the matrix with the same factor per axis.

Now, considering the identity matrix, we can scale a vector by changing the 1's in the diagonal with the factors we
want:

#+CAPTION: Scaling Vector With Matrix
#+NAME: ScalingVectorWithMatrix.png
[[./ScalingVectorWithMatrix.png]]

We let the 4th component to 1 for now. This corresponds to the W component in OpenGL.

**** Translation
It's adding another vector on top of the original vector. This yields a new vector with a different position.

This means we're "moving" the original vector based on a translation vector.

Again, we use the identity matrix to perform this operation. In this case and because we have 4 components (it wouldn't
work with 3) we can do this trick:

#+CAPTION: Translation Matrix
#+NAME: TranslationMatrix.png
[[./TranslationMatrix.png]]

Where T's are the components of the translation vector and x,y,z is the original vector.

With a translation matrix we can move any object in the 3 axis directions.

**** Homogeneous Coordinates
The W component of a vector is known as a homogeneous coordinate.

If we want to get the 3D vector of a homogeneous vector (4D), we need to divide each component by the W coordinate.

Usually this component has the value 1.0.

It helps us translate 3D vectors and to create 3D perspective.

If the W coordinate is 0.0, then the vector is known to be a _direction vector_ because it cannot be translated.

**** Rotation
Rotation means rotating an object over an axis with a certain angle.

To rotate 2D objects in OpenGL, we only need to provide the angle and the rotation axis as the Z-axis.

To rotate 3D objects, we need to provide the angle and the rotation axis (the one that will remain fixed over the
duration of the rotation).

To transform vectors to rotate them (rotated vectors), depending on the axis we want to rotate on, we can use these
matrices:

Rotation around the X-axis:

#+CAPTION: Rotation Matrix X Axis
#+NAME: RotationMatrixXAxis.png
[[./RotationMatrixXAxis.png]]

Rotation around the Y-axis:

#+CAPTION: Rotation Matrix Y Axis
#+NAME: RotationMatrixYAxis.png
[[./RotationMatrixYAxis.png]]

Rotation around the Z-axis:

#+CAPTION: Rotation Matrix Z Axis
#+NAME: RotationMatrixZAxis.png
[[./RotationMatrixZAxis.png]]

NOTE: To rotate around an arbitrary 3D axis we'd need to use a more complex matrix or quaternions.

NOTE: Keep in mind that the axis that we rotate around should be a unit vector, so be sure to normalize the vector first
if you're not rotating around the X, Y, or Z axis.

*** Combining Matrices
Matrices are awesome because we can mix multiple transformation matrices in a single matrix to then modify a vector.

For example, say we have our vector (x, y, z) and we wanted to scale it by 2 and then translate it by (1, 2, 3).

Our combination of scale and translate matrix would look like this:

#+CAPTION: Transformation Matrix Combination
#+NAME: TransformationMatrixCombination.png
[[./TransformationMatrixCombination.png]]

It's important _to remember that matrix multiplication is not commutative_, so we first translate and then scale.

It's important to read the multiplication from right to left (math. properties).

NOTE: _It is advised to first do scaling operations, then rotations and lastly translations when combining matrices
otherwise they may (negatively) affect each other_.

You can see in this image that the vector is firstly scaled by 2 and then translated by 1, 2 and 3!

#+CAPTION: Transformation Matrix Combination End
#+NAME: TransformationMatrixCombinationEnd.png
[[./TransformationMatrixCombinationEnd.png]]

*** Parallelogram Law
TODO

*** Read, TODO
In order:

- https://www.khanacademy.org/math/geometry-home/right-triangles-topic/intro-to-the-trig-ratios-geo/v/basic-trigonometry
- https://www.khanacademy.org/math/algebra-home/alg-matrices
- https://www.khanacademy.org/math/linear-algebra/matrix-transformations
- https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab

We need to understand the explanation and REALLY how the two exercises of the "Transformations" chapter work. If we
don't, we'll never get good at this.
